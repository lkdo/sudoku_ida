{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from math import ceil\n",
    "import os \n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "#CV2 version:  4.8.0\n",
    "#Numpy version:  1.25.2\n",
    "#Tesseract version:  0.3.10\n",
    "\n",
    "print(\"CV2 version: \", cv2.getVersionString())\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Tesseract version: \", pytesseract.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose image\n",
    "\n",
    "output_folder = \"./outputStages/Pipeline_0/\"\n",
    "\n",
    "#input_image = \"./data/computer_generated_images/Sudoku_puzzle_hard_for_brute_force.jpg\"  # https://commons.wikimedia.org/wiki/File:Sudoku_puzzle_hard_for_brute_force.jpg\n",
    "#output_basename =  \"Sudoku_puzzle_hard_for_brute_force\"\n",
    "\n",
    "input_image = \"./data/computer_generated_images/Sudoku_Puzzle_by_L2G-20050714_standardized_layout.svg.png\"  # https://upload.wikimedia.org/wikipedia/commons/e/e0/Sudoku_Puzzle_by_L2G-20050714_standardized_layout.svg\n",
    "output_basename =  \"Sudoku_Puzzle_by_L2G-20050714_standardized_layout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printoutStage(stage_no, stage_img):\n",
    "    global output_folder, output_basename\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(\"Made designated output folder\")\n",
    "    cv2.imwrite(output_folder + output_basename + \"-stage-\" + str(stage_no) +\".png\", stage_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image as gray scale \n",
    "image = cv2.imread(input_image)\n",
    "img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ----------------\n",
    "printoutStage(1, img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Blur\n",
    "image = img_gray\n",
    "img_blur = cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "\n",
    "# ----------------\n",
    "printoutStage(2, img_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Threshold\n",
    "\n",
    "image = img_blur \n",
    "\n",
    "def apply_adaptive_threshold(image, block_size=11, constant_value=2):\n",
    "    v1 = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "    v2 = cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "    # Apply adaptive thresholding\n",
    "    thresholded_image = cv2.adaptiveThreshold(\n",
    "        image, 255, v2,\n",
    "        cv2.THRESH_BINARY, block_size, constant_value\n",
    "    )\n",
    "    return thresholded_image\n",
    "\n",
    "# Specify block size and constant value for adaptive thresholding\n",
    "block_size = 11\n",
    "constant_value = 2\n",
    "\n",
    "# Apply adaptive thresholding to the image\n",
    "img_thrsh = apply_adaptive_threshold(image, block_size, constant_value)\n",
    "\n",
    "# ----------------\n",
    "printoutStage(3, img_thrsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by finding contours in the thresholded image:\n",
    "\n",
    "image = img_thrsh\n",
    "\n",
    "contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#print(len(contours), contours[0])\n",
    "#print(hierarchy)\n",
    "\n",
    "img_contours = image.copy()\n",
    "img_contours_color = cv2.cvtColor(img_contours, cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image=img_contours_color, contours=contours, \n",
    "  contourIdx = -1, color = (0,255,0), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "# ----------------\n",
    "printoutStage(4, img_contours_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the 4-corner approximations for all rectangle contours\n",
    "image = img_thrsh\n",
    "\n",
    "approxes = []\n",
    "for idx, contour in enumerate(contours):\n",
    "    area = cv2.contourArea(contour)\n",
    "    peri = cv2.arcLength(contour,True)\n",
    "    approx = cv2.approxPolyDP(contour,0.02*peri,True)\n",
    "    if len(approx)==4: \n",
    "        approxes.append(approx)\n",
    "print(\"Number of contour approxes: ( should be at least 82 )\", len(approxes))\n",
    "\n",
    "# plot them for me\n",
    "img_contours = image.copy()\n",
    "img_contours_color = cv2.cvtColor(img_contours, cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image=img_contours_color, contours=approxes, \n",
    "    contourIdx = -1 , color = (0,255,0), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "# ----------------\n",
    "printoutStage(5, img_contours_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the contour approx area which has exactly 81 repetitions \n",
    "approx_areas = np.array([])\n",
    "approx_areas_idxs = []\n",
    "for idx, approx in enumerate(approxes):\n",
    "    area = cv2.contourArea(approx)\n",
    "    x = np.where( (approx_areas >= 0.85*area) & (approx_areas <= 1.15*area) )\n",
    "    # print(idx, area, approx_areas, x, len(x))\n",
    "    # x contains at least idx\n",
    "    if len(x[0]) == 0:\n",
    "        print(\"First time we met this area size\")\n",
    "        approx_areas = np.append(approx_areas,area)\n",
    "        approx_areas_idxs.append([idx])    \n",
    "    elif len(x[0]) == 1:\n",
    "        #print(\"Not the first time we met this area size, add index to area size index list \")\n",
    "        approx_areas_idxs[x[0][0]].append(idx)\n",
    "    elif len(x[0]) > 1:\n",
    "        print(\"This is a problem!\")    \n",
    "    \n",
    "# one length should be 81\n",
    "approx_areas_idxs_lens = np.array([])\n",
    "for idxs in approx_areas_idxs:\n",
    "    approx_areas_idxs_lens = np.append(approx_areas_idxs_lens, len(idxs))\n",
    "\n",
    "print(\"approx areas:\", approx_areas)\n",
    "print(\"approx areas idxs:\", approx_areas_idxs)\n",
    "print(\"approx areas idxs lens:\", approx_areas_idxs_lens)\n",
    "\n",
    "x = np.where(approx_areas_idxs_lens == 81)\n",
    "if len(x[0])==0 or len(x[0])>1:\n",
    "    print(\"\\n\\nERROR did not find the correct small squares\")\n",
    "else:\n",
    "    sq_idxs = sorted(approx_areas_idxs[x[0][0]])\n",
    "    print(\"\\n\\nALL OK ! idx of small squares in \\\"approxes\\\" is:\", sq_idxs)\n",
    "    # work only with the little squares blob approximations\n",
    "    approxes_sq = np.array(approxes)[sq_idxs].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function, needed later\n",
    "# cluster a set of values into clusters of size k\n",
    "# by sorting the data set and then grouping into the cluster size \n",
    "def my_cluster(x, k=2):\n",
    "   # y = sorted(x)\n",
    "   idx = sorted(range(len(x)), key=lambda j: x[j])\n",
    "   y = [x[j] for j in idx]\n",
    "\n",
    "   # sanity check todo\n",
    "   clusters = []\n",
    "   means = []\n",
    "   idx_clustered = []\n",
    "   for i in range(ceil(len(y)/k)):\n",
    "      clusters.append(y[i*k:(i+1)*k])\n",
    "      idx_clustered.append(idx[i*k:(i+1)*k])\n",
    "      means.append(np.mean(clusters[-1]))\n",
    "   return clusters, means, idx_clustered \n",
    "\n",
    "# unit test of function \n",
    "print(my_cluster([10,10.5,8.1,7.9,6.3,5.9,14.2,14.3,2,1]))\n",
    "print(my_cluster([10,10.5,8.1,7.9,6.3,5.9,14.2,14.3,2,1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to order the approxes by coordinates, to get the numbers in right order !\n",
    "boxes = []\n",
    "boxes_ulc = []  # upper left corner only\n",
    "for idx, approx in enumerate(approxes_sq):\n",
    "    approx = np.array(approx)\n",
    "    boxes.append([ my_cluster(approx[:,0,0])[1] , my_cluster(approx[:,0,1])[1] ])   # [ [xmin, xmax] , [ymin,y_max] ] \n",
    "    boxes_ulc.append([boxes[-1][0][0],boxes[-1][1][0]])  # [ [xmin, ymin ] ] \n",
    "print(len(boxes), boxes, \"\\n\\n\", len(boxes_ulc), boxes_ulc, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to sort the boxes\n",
    "# We need to cluster y in 9 rows\n",
    "row_clusters, row_y_coords, row_idxs = my_cluster(np.array(boxes_ulc)[:,1].tolist(),9)\n",
    "\n",
    "# Safety checks\n",
    "for i, c in enumerate(row_clusters):\n",
    "    if len(c) != 9:\n",
    "       print(\"ERROR not 9\") \n",
    "if len(row_y_coords) != 9:\n",
    "    print(\"ERROR not 9\")\n",
    "\n",
    "print(\"row_clusters:\", row_clusters)\n",
    "print(\"row_y_coords:\", row_y_coords)\n",
    "print(\"row_idxs:\", row_idxs, \"\\n\")\n",
    "\n",
    "row_idxs_x_sorted = []\n",
    "# I need to sort the x also now, so inside every idx cluster, I need to resort \n",
    "for i, idx_cluster in enumerate(row_idxs):\n",
    "    # e.g. idx_cluster = [63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
    "    \n",
    "    # build the x coordinate list corresponding to this cluster \n",
    "    x_coords = []\n",
    "    for j in idx_cluster:\n",
    "        x_coords.append(np.array(boxes_ulc)[j,0])\n",
    "    print(\"x_coords:\", x_coords)        \n",
    "    \n",
    "    # I need x_coords indices sorted\n",
    "    idx_x_coords_sorted = sorted(range(len(x_coords)), key = lambda j: x_coords[j])\n",
    "    x_coords_sorted = [x_coords[j] for j in idx_x_coords_sorted]\n",
    "\n",
    "    # print for visual inspection\n",
    "    print(\"x_coords_sorted:\", x_coords_sorted)\n",
    "    print(\"New sorting of index cluster:\",np.array(idx_cluster)[idx_x_coords_sorted].tolist())\n",
    "    \n",
    "    row_idxs_x_sorted.append(np.array(idx_cluster)[idx_x_coords_sorted].tolist())\n",
    "    print(row_idxs_x_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row_idxs_x_sorted) # sorted version\n",
    "\n",
    "for i in range(len(approxes_sq)):\n",
    "    approxes_sq[i] = np.array(approxes_sq[i])\n",
    "\n",
    "# Single test\n",
    "# img_contours_color4 = cv2.cvtColor(img_contours_2, cv2.COLOR_GRAY2RGB)\n",
    "# cv2.drawContours(image=img_contours_color4, contours = approxes_sq, \n",
    "#     contourIdx = row_idxs_x_sorted[2][7] , color = (0,255,0), thickness=3, lineType=cv2.LINE_AA)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.imshow('image6', img_contours_color4)\n",
    "# cv2.waitKey(1)\n",
    "\n",
    "# full visual inspection from stiching back\n",
    "PSIZE = -1\n",
    "img_all = np.array([])\n",
    "for idxs in row_idxs_x_sorted:\n",
    "    img_row = np.array([])\n",
    "    for idx in idxs: \n",
    "        y_min = int(boxes[idx][1][0])\n",
    "        y_max = int(boxes[idx][1][1])\n",
    "        x_min = int(boxes[idx][0][0])\n",
    "        x_max = int(boxes[idx][0][1])\n",
    "        img_new = img_gray[y_min:y_max, x_min:x_max]\n",
    "        if (PSIZE == -1):\n",
    "            PSIZE = abs(max(x_max-x_min, y_max-y_min)*2)\n",
    "        v0 = int(PSIZE - img_new.shape[0])\n",
    "        v1 = int(PSIZE - img_new.shape[1])\n",
    "        img_new_padded = np.pad(img_new, ((0, v0), (0, v1)), 'constant', constant_values=100)\n",
    "        print(\"Shapes:\\t\", img_new.shape, img_new_padded.shape, img_row.shape)\n",
    "        if len(img_row):\n",
    "            img_row = np.concatenate( (img_row, img_new_padded), axis = 1 ) # stack horizontally\n",
    "        else:\n",
    "            img_row = img_new_padded\n",
    "    if len(img_all):\n",
    "        img_all = np.concatenate((img_all, img_row), axis=0) # stack vertically\n",
    "    else:\n",
    "        img_all = img_row\n",
    "\n",
    "\n",
    "# ----------------\n",
    "stage = 6\n",
    "img_stage = img_all\n",
    "cv2.imwrite(output_folder + output_basename + \"-stage-\" + str(stage) +\".png\", img_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each little square box and OCR the digit;\n",
    "# But also plot the visual inspection segmentation\n",
    "# print(boxes)\n",
    "\n",
    "PSIZE = -1\n",
    "img_all = np.array([])\n",
    "img_row = np.array([])\n",
    "ctr = 0\n",
    "\n",
    "SUDOKU_MATRIX = np.zeros([9,9])\n",
    "ii = 0\n",
    "for idxs in row_idxs_x_sorted:\n",
    "    jj = 0\n",
    "    for idx in idxs: \n",
    "        y_min = int(boxes[idx][1][0])\n",
    "        y_max = int(boxes[idx][1][1])\n",
    "        x_min = int(boxes[idx][0][0])\n",
    "        x_max = int(boxes[idx][0][1])\n",
    "        \n",
    "        #ROI = img_gray[y_min:y_max, x_min:x_max]\n",
    "        ROI = img_gray[y_min:y_max, x_min:x_max]\n",
    "        print(\"Shape:\\t\", ROI.shape)\n",
    "        ocr_result = \"\"\n",
    "\n",
    "        # code for segmentation stiching \n",
    "        # ------------------------------------------------\n",
    "        if (PSIZE == -1):\n",
    "            PSIZE = abs(max(x_max-x_min, y_max-y_min)*2)\n",
    "        v0 = int(PSIZE - ROI.shape[0])\n",
    "        v1 = int(PSIZE - ROI.shape[1])\n",
    "        ROI_padded = np.pad(ROI, ((0, v0), (0, v1)), 'constant', constant_values=100)\n",
    "        if len(img_row):\n",
    "            img_row = np.concatenate( (img_row, ROI_padded), axis = 1 ) # stack horizontally\n",
    "        else:\n",
    "            img_row = ROI_padded\n",
    "        ctr = ctr + 1\n",
    "        if ctr == 9:\n",
    "          ctr = 0\n",
    "          if len(img_all):\n",
    "            img_all = np.concatenate((img_all, img_row), axis=0) # stack vertically\n",
    "          else:\n",
    "            img_all = img_row\n",
    "          img_row = np.array([]) \n",
    "        # ------------------------------------------------\n",
    "\n",
    "        # Threshold analysis, because of tesseract identifying  characters where there are none\n",
    "        # Calculate the percentage of non-white pixels\n",
    "        #non_white_pixels = cv2.countNonZero(ROI)\n",
    "        non_white_pixels = ( ROI.flatten() < 155 ).sum()\n",
    "        total_pixels = ROI.shape[0] * ROI.shape[1]\n",
    "        non_white_ratio = non_white_pixels / total_pixels\n",
    "        print(\"Non White Ratio Result: \", idx, non_white_ratio)\n",
    "\n",
    "        # Compare the non-white ratio with the threshold\n",
    "        if non_white_ratio >= 0.025:\n",
    "            _, thresholded = cv2.threshold(ROI, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Specify your whitelist of characters. We want only digits:\n",
    "            ocr_result = pytesseract.image_to_string(thresholded, config = r'--psm 10 -c tessedit_char_whitelist=123456789')\n",
    "            ocr_result = ocr_result.strip()\n",
    "           \n",
    "            print(\"OCR Result: \", idx, ocr_result)\n",
    "            SUDOKU_MATRIX[ii,jj] =  int(ocr_result)\n",
    "        jj = jj + 1\n",
    "    \n",
    "    ii = ii + 1    \n",
    "\n",
    "#------------------\n",
    "printoutStage(10,img_all)\n",
    "\n",
    "####################\n",
    "# # Page segmentation modes:\n",
    "#  0    Orientation and script detection (OSD) only.\n",
    "#  1    Automatic page segmentation with OSD.\n",
    "#  2    Automatic page segmentation, but no OSD, or OCR.\n",
    "#  3    Fully automatic page segmentation, but no OSD. (Default)\n",
    "#  4    Assume a single column of text of variable sizes.\n",
    "#  5    Assume a single uniform block of vertically aligned text.\n",
    "#  6    Assume a single uniform block of text.\n",
    "#  7    Treat the image as a single text line.\n",
    "#  8    Treat the image as a single word.\n",
    "#  9    Treat the image as a single word in a circle.\n",
    "# 10    Treat the image as a single character.\n",
    "# 11    Sparse text. Find as much text as possible in no particular order.\n",
    "# 12    Sparse text with OSD.\n",
    "# 13    Raw line. Treat the image as a single text line,\n",
    "#                        bypassing hacks that are Tesseract-specific.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SUDOKU MATRIX:\\n\", SUDOKU_MATRIX)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
