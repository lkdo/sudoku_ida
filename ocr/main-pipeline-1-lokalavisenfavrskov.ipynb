{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the used libraries into the script\n",
    "# ---------------------------------------------\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "from math import ceil, floor\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "#CV2 version:  4.8.0\n",
    "#Numpy version:  1.25.2\n",
    "#Tesseract version:  0.3.10\n",
    "\n",
    "print(\"CV2 version: \", cv2.getVersionString())\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Tesseract version: \", pytesseract.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select input file and define the output folder\n",
    "# ---------------------------------------------\n",
    "\n",
    "global output_folder, output_basename\n",
    "\n",
    "output_folder = \"./outputStages/Pipeline_1/\"\n",
    "\n",
    "input_image = \"./data/newspaper_lokalavisenfavrskov/S1.jpg\"\n",
    "output_basename = \"S1\"\n",
    "\n",
    "#input_image = \"./data/newspaper_lokalavisenfavrskov/S2.jpg\"\n",
    "#output_basename = \"S2\"\n",
    "\n",
    "#input_image = \"./data/computer_generated_images/Sudoku_Puzzle_by_L2G-20050714_standardized_layout.svg.png\"  # https://upload.wikimedia.org/wikipedia/commons/e/e0/Sudoku_Puzzle_by_L2G-20050714_standardized_layout.svg\n",
    "#output_basename =  \"Sudoku_Puzzle_by_L2G-20050714_standardized_layout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for visualization of intermediary/stage results\n",
    "# ---------------------------------------------\n",
    "def printoutStage(stage_no, stage_img):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(\"Made designated output folder\")\n",
    "    cv2.imwrite(output_folder + output_basename + \"-stage-\" + str(stage_no) +\".png\", stage_img)\n",
    "    cv2.imwrite(output_folder + \"last.png\", stage_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image\n",
    "# ------------ \n",
    "image = cv2.imread(input_image)\n",
    "img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ------------\n",
    "printoutStage(1, img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Threshold \"white-en\" image\n",
    "# -----------------------------------\n",
    "image = img_gray\n",
    "\n",
    "def apply_adaptive_threshold(image, block_size=11, constant_value=2):\n",
    "\n",
    "    v1 = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "    v2 = cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "    # Apply adaptive thresholding\n",
    "    thresholded_image = cv2.adaptiveThreshold(\n",
    "        image, 255, v2,\n",
    "        cv2.THRESH_BINARY, block_size, constant_value\n",
    "    )\n",
    "\n",
    "    return thresholded_image\n",
    "\n",
    "# Specify block size and constant value for adaptive thresholding for segmentation\n",
    "block_size = int(image.shape[0]/9/4)\n",
    "if block_size % 2 == 0:\n",
    "   block_size =  block_size - 1 \n",
    "\n",
    "constant_value = 15     # For S1 image \n",
    "#constant_value = 5     # For S2 image\n",
    "\n",
    "# Apply adaptive thresholding to the image\n",
    "img_threshold = apply_adaptive_threshold(image, block_size, constant_value)\n",
    "\n",
    "# ------------\n",
    "printoutStage(2.1, img_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinforce the outer lines of the grid \n",
    "# using dilation operation on inverse black and white \n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "image = img_threshold\n",
    "img_inv = cv2.bitwise_not(image)\n",
    "# ---------\n",
    "printoutStage(3.1, img_inv)\n",
    "\n",
    "\n",
    "# Dilation 1\n",
    "image = img_inv\n",
    "no_dilatation_iter = 4\n",
    "\n",
    "# Define a structuring element\n",
    "structuring_element = np.ones((3,1), np.uint8) # horiz line\n",
    "img_dilated_horiz = cv2.dilate(image, structuring_element, iterations=no_dilatation_iter)\n",
    "# ---------\n",
    "printoutStage(3.2, img_dilated_horiz)\n",
    "\n",
    "\n",
    "# Dilation 2\n",
    "image = img_dilated_horiz\n",
    "# For vertical lines, you might use:\n",
    "structuring_element = np.ones((1,3), np.uint8) # vertical line\n",
    "img_dilated_horiz_verti = cv2.dilate(image, structuring_element, iterations=no_dilatation_iter)\n",
    "# ---------\n",
    "printoutStage(3.3, img_dilated_horiz_verti)\n",
    "\n",
    "image = img_dilated_horiz_verti\n",
    "#img_reinforced = cv2.bitwise_not(image)\n",
    "img_reinforced = image\n",
    "\n",
    "# ------------\n",
    "printoutStage(3.4, img_reinforced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the main sudoku box\n",
    "# -------------------------\n",
    "image = img_reinforced\n",
    "#contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "contours, hierarchy = cv2.findContours(image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    " \n",
    "print(len(contours), contours[0])\n",
    "\n",
    "img_contours = image.copy()\n",
    "img_contours_color = cv2.cvtColor(img_contours, cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image=img_contours_color, contours=contours, \n",
    " contourIdx = -1, color = (0,255,0), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "# ------------\n",
    "printoutStage(4.1, img_contours_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 4 cornered approximations for the contours\n",
    "# -----------------------------------------------------\n",
    "image = img_reinforced\n",
    "\n",
    "approxes = []\n",
    "for idx, contour in enumerate(contours):\n",
    "    area = cv2.contourArea(contour)\n",
    "    peri = cv2.arcLength(contour,True)\n",
    "    approx = cv2.approxPolyDP(contour,0.03*peri,True)\n",
    "    if len(approx)==4: \n",
    "        approxes.append(approx)\n",
    "print(\"Number of 4-cornered contour approxes: (should be close to 80 on a clean image )\", len(approxes))\n",
    "\n",
    "img_contours = image.copy()\n",
    "img_contours_color = cv2.cvtColor(img_contours, cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image=img_contours_color, contours=approxes, \n",
    "    contourIdx = -1 , color = (0,255,0), thickness=8, lineType=cv2.LINE_AA)\n",
    "\n",
    "# ------------\n",
    "printoutStage(4.2, img_contours_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the main sudoku frame/box by\n",
    "# Finding the minimum area 4-cornered-contour from all those\n",
    "# that have an area bigger than 80% of the image\n",
    "# ---------------------------------------------------------\n",
    "areas = []\n",
    "image = img_reinforced\n",
    "\n",
    "img_height, img_width = image.shape[:2]\n",
    "img_area = img_height * img_width\n",
    "print(\"IMG Height:\", img_height, \"IMG Width:\", img_width, \"IMG Area:\", img_area)\n",
    "\n",
    "for idx, approx in enumerate(approxes):\n",
    "    areas.append(cv2.contourArea(approx))\n",
    "\n",
    "idx_sorted_areas = sorted(range(len(areas)), key=lambda j: areas[j], reverse=True)\n",
    "sorted_areas = [areas[j] for j in idx_sorted_areas]\n",
    "\n",
    "print(sorted_areas)\n",
    "\n",
    "idx_big_box_candidates = np.where(np.array(sorted_areas) > 0.7 * img_area)\n",
    "if len(idx_big_box_candidates[0]) == 0:\n",
    "   print(\"Error\") \n",
    "    \n",
    "print(\"idx_big_box_candidates\", idx_big_box_candidates)\n",
    "\n",
    "# Hopefully got the bigbox candiatate correctly!\n",
    "big_box_idx = idx_big_box_candidates[0][-1]\n",
    "big_box_area = sorted_areas[big_box_idx]\n",
    "print(\"Big Box area idx:\\t\", big_box_idx)\n",
    "print(\"Big box area:\\t \", big_box_area)\n",
    "\n",
    "true_big_box_idx = idx_sorted_areas[big_box_idx]\n",
    "print(\"Big Box Actual Id:\", true_big_box_idx)\n",
    "\n",
    "# plot the big box \n",
    "img_bigbox = image.copy()\n",
    "img_bigbox_color = cv2.cvtColor(img_bigbox, cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image=img_bigbox_color, contours=approxes, \n",
    "    contourIdx = true_big_box_idx , color = (0,255,0), thickness=12, lineType=cv2.LINE_AA)\n",
    "\n",
    "big_box = approxes[true_big_box_idx]\n",
    "print(\"Big Box:\\t\", big_box)\n",
    "\n",
    "# ------------\n",
    "printoutStage(4.3, img_bigbox_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup everything outside this box (make it white)\n",
    "# ---------------------------------------------\n",
    "\n",
    "image = img_reinforced\n",
    "\n",
    "# original image\n",
    "mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "cv2.fillPoly(mask, pts=[big_box[:,0,:]], color=(255))\n",
    "\n",
    "# apply the mask\n",
    "wbg = np.ones_like(image, np.uint8)*255\n",
    "cv2.bitwise_not(wbg,wbg, mask=mask)\n",
    "img_reinforced_cleaned = wbg + cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "# ------------\n",
    "printoutStage(4.4, img_reinforced_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Perspective:\n",
    "# (a) Generate the ideal / straight outer box\n",
    "# ---------------------------------------------\n",
    "\n",
    "big_box_n = big_box[:,0,:]\n",
    "idx = [ [0,1], [1,2], [2,3], [3,0] ]\n",
    "lengs = []\n",
    "for i, idx_pair in enumerate(idx):\n",
    "   x1 = big_box_n[idx_pair[0],0] \n",
    "   y1 = big_box_n[idx_pair[0],1]\n",
    "   x2 = big_box_n[idx_pair[1],0]\n",
    "   y2 = big_box_n[idx_pair[1],1]\n",
    "   lengs.append(np.sqrt((x1-x2)**2+(y2-y1)**2))\n",
    "\n",
    "len_side = int(np.mean(lengs))\n",
    "\n",
    "# --------\n",
    "\n",
    "big_box_xs = []\n",
    "big_box_ys = []\n",
    "\n",
    "for i in range(4):\n",
    "   big_box_xs.append(big_box_n[i,0])\n",
    "   big_box_ys.append(big_box_n[i,1])\n",
    "\n",
    "big_box_xs = sorted(big_box_xs)\n",
    "big_box_ys = sorted(big_box_ys)\n",
    "\n",
    "print(\"xs:\\t\", big_box_xs)\n",
    "print(\"ys:\\t\", big_box_ys)\n",
    "\n",
    "x_min = np.mean(big_box_xs[0:2])\n",
    "x_max = np.mean(big_box_xs[2:4])\n",
    "\n",
    "y_min = np.mean(big_box_ys[0:2])\n",
    "y_max = np.mean(big_box_ys[2:4])\n",
    "\n",
    "# ---------\n",
    "\n",
    "str8_box = []\n",
    "ulc = [[ x_min, y_min ]]\n",
    "urc = [[ x_min+len_side, y_min ]]\n",
    "lrc = [[ x_min+len_side, y_min+len_side ]]\n",
    "llc = [[ x_min, y_min+len_side ]]\n",
    "str8_box.append(np.array([ulc, urc, lrc, llc], dtype=int))\n",
    "\n",
    "# Enforce the same convention order convention for the big_box corners, otherwise e.g. 90 degrees rotations\n",
    "# Sort by y-coordinate\n",
    "bbox = sorted(big_box[:,0,:], key=lambda pt: pt[1])\n",
    "# Separate the box points into top and bottom\n",
    "btop = sorted(bbox[:2], key=lambda pt: pt[0])  # Top-left and top-right\n",
    "bbottom = sorted(bbox[2:], key=lambda pt: pt[0], reverse=True)  # Bottom-right and bottom-left\n",
    "# Now, concatenate the boxes again\n",
    "big_box_n_conform = np.array(btop + bbottom)\n",
    "\n",
    "\n",
    "# plot the generated grid ontop of image\n",
    "image = img_reinforced_cleaned\n",
    "img_outer_box = image.copy()\n",
    "img_outer_box_color = cv2.cvtColor(img_outer_box, cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image=img_outer_box_color, contours=str8_box, \n",
    "    contourIdx = -1 , color = (0,255,0), thickness=ceil(img_outer_box.shape[0]/90), lineType=cv2.LINE_AA)\n",
    "\n",
    "# ------------\n",
    "printoutStage(5.1, img_outer_box_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Perspective:\n",
    "# (b) find the Perspective transform \n",
    "# ---------------------------------------------\n",
    "warp_matrix = cv2.getPerspectiveTransform(str8_box[0][:,0,:].astype(np.float32), big_box_n_conform.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Perspective:\n",
    "# (c) Apply the perspective transform to the full image\n",
    "# ---------------------------------------------\n",
    "\n",
    "def align_apply2image(img, warp_matrix):\n",
    "  return cv2.warpPerspective(img, warp_matrix, \n",
    "    (img.shape[1], img.shape[0]), \n",
    "    flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "img_gray_aligned = align_apply2image(img_gray, warp_matrix)\n",
    "\n",
    "img_gray_aligned_c = cv2.cvtColor(img_gray_aligned.copy(), cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image = img_gray_aligned_c, contours=str8_box, \n",
    "    contourIdx = -1 , color = (0,255,0), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "img_threshold_aligned = align_apply2image(img_threshold, warp_matrix)\n",
    "\n",
    "img_threshold_aligned_c = cv2.cvtColor(img_threshold_aligned.copy(), cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image = img_threshold_aligned_c, contours=str8_box, \n",
    "    contourIdx = -1 , color = (0,255,0), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "#------------------\n",
    "printoutStage(5.2,img_gray_aligned_c)\n",
    "printoutStage(5.3,img_threshold_aligned_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a full str8 grid\n",
    "# ---------------------------------------------\n",
    "\n",
    "image = img_gray_aligned\n",
    "\n",
    "dx = len_side/9.0\n",
    "\n",
    "grid_xs = np.arange(x_min, x_max + 0.9*dx, dx)\n",
    "grid_ys = np.arange(y_min, y_max + 0.9*dx, dx)\n",
    "\n",
    "# ---------\n",
    "# Generate a set of artificial roi boxes\n",
    "print(\"Grid xs:\\t\", grid_xs)\n",
    "print(\"Grid ys:\\t\", grid_ys)\n",
    "\n",
    "# Generate the boxes to plot\n",
    "generated_roi_boxes = []\n",
    "for jj in range(9):\n",
    "   for ii in range(9):\n",
    "      ulc = [[ grid_xs[ii], grid_ys[jj] ]]\n",
    "      urc = [[ grid_xs[ii+1], grid_ys[jj] ]]\n",
    "      llc = [[ grid_xs[ii], grid_ys[jj+1] ]]\n",
    "      lrc = [[ grid_xs[ii+1], grid_ys[jj+1] ]]\n",
    "      generated_roi_boxes.append(np.array([ulc, urc, lrc, llc], dtype=int))\n",
    "\n",
    "# plot the generated grid ontop of image\n",
    "img_grid = image.copy()\n",
    "img_grid_color = cv2.cvtColor(img_grid, cv2.COLOR_GRAY2RGB)\n",
    "cv2.drawContours(image=img_grid_color, contours=generated_roi_boxes, \n",
    "    contourIdx = -1 , color = (0,255,0), thickness=ceil(img_grid_color.shape[0]/90), lineType=cv2.LINE_AA)\n",
    "\n",
    "# ------------ \n",
    "printoutStage(5.4, img_grid_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image for OCR: Do a blur\n",
    "# -----------------------------------\n",
    "img_threshold_aligned_blur = cv2.GaussianBlur(img_threshold_aligned, (5,5), 0)\n",
    "img_gray_aligned_blur = cv2.GaussianBlur(img_gray_aligned, (5,5), 0)\n",
    "\n",
    "# ------------\n",
    "printoutStage(6.1, img_threshold_aligned_blur)\n",
    "printoutStage(6.15, img_gray_aligned_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image for OCR: Do a closing\n",
    "# ---------------\n",
    "structuring_element = np.ones((11, 11), np.uint8) \n",
    "img_threshold_aligned_blur_closed = cv2.bitwise_not(cv2.morphologyEx(cv2.bitwise_not(img_threshold_aligned_blur), cv2.MORPH_CLOSE, structuring_element))\n",
    "img_gray_aligned_blur_closed = cv2.bitwise_not(cv2.morphologyEx(cv2.bitwise_not(img_gray_aligned_blur), cv2.MORPH_CLOSE, structuring_element))\n",
    "\n",
    "# ------------\n",
    "printoutStage(6.2, img_threshold_aligned_blur_closed)\n",
    "#printoutStage(6.25, img_gray_aligned_blur_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each little square box and OCR the digit with Tesseract\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "image = img_threshold_aligned_blur_closed\n",
    "\n",
    "SUDOKU_MATRIX_TESSERACT = np.zeros([9,9])\n",
    "\n",
    "PSIZE = -1\n",
    "img_all = np.array([])\n",
    "img_row = np.array([])\n",
    "ctr = 0\n",
    "\n",
    "for idx in range(81):\n",
    "  \n",
    "  ii = idx//9 \n",
    "  jj = idx%9 \n",
    "\n",
    "  y_min = np.min( [generated_roi_boxes[idx][0][0][1], generated_roi_boxes[idx][1][0][1], generated_roi_boxes[idx][2][0][1], generated_roi_boxes[idx][3][0][1]] )\n",
    "  y_max = np.max( [generated_roi_boxes[idx][0][0][1], generated_roi_boxes[idx][1][0][1], generated_roi_boxes[idx][2][0][1], generated_roi_boxes[idx][3][0][1]] )\n",
    "  x_min = np.min( [generated_roi_boxes[idx][0][0][0], generated_roi_boxes[idx][1][0][0], generated_roi_boxes[idx][2][0][0], generated_roi_boxes[idx][3][0][0]] )\n",
    "  x_max = np.max( [generated_roi_boxes[idx][0][0][0], generated_roi_boxes[idx][1][0][0], generated_roi_boxes[idx][2][0][0], generated_roi_boxes[idx][3][0][0]] )\n",
    "  \n",
    "  # Cut a bit the edges so we eliminate black lines from the grid\n",
    "  # For the OCR to work better \n",
    "  \n",
    "  delta_x = floor(0.075*(x_max-x_min))  \n",
    "  delta_y = floor(0.075*(y_max-y_min)) \n",
    "   \n",
    "  ROI = image[y_min+delta_y:y_max-delta_y, x_min+delta_x:x_max-delta_x]\n",
    "\n",
    "  non_white_pixels = ( ROI.flatten() < 155 ).sum()\n",
    "  total_pixels = ROI.shape[0] * ROI.shape[1]\n",
    "  non_white_ratio = non_white_pixels / total_pixels\n",
    "  print(\"Non White Ratio Result: \", idx, non_white_ratio)\n",
    "   \n",
    "  # Do a white padding for the OCR to work better \n",
    "  # -----------------------------------------------\n",
    "  #pad_y = 15\n",
    "  #pad_x = 15 \n",
    "\n",
    "  # Pad the matrix with white \n",
    "  # ROI = np.pad(ROI, ((pad_y, pad_y), (pad_x, pad_x)), mode='constant', constant_values=255)\n",
    "\n",
    "  # Resize to 32 x 32 \n",
    "  ROI = cv2.resize(ROI, (32,32), interpolation = cv2.INTER_AREA)\n",
    "   \n",
    "  # code for to see the segmentation \n",
    "  # ------------------------------------------------\n",
    "  if (PSIZE == -1):\n",
    "      PSIZE = abs(max(ROI.shape[0], ROI.shape[1])*1.1)\n",
    "  v0 = int(PSIZE - ROI.shape[0])\n",
    "  v1 = int(PSIZE - ROI.shape[1])\n",
    "  ROI_padded = np.pad(ROI, ((0, v0), (0, v1)), 'constant', constant_values=100)\n",
    "  if len(img_row):\n",
    "      img_row = np.concatenate( (img_row, ROI_padded), axis = 1 ) # stack horizontally\n",
    "  else:\n",
    "      img_row = ROI_padded\n",
    "  ctr = ctr + 1\n",
    "  if ctr == 9:\n",
    "    ctr = 0\n",
    "    if len(img_all):\n",
    "      img_all = np.concatenate((img_all, img_row), axis=0) # stack vertically\n",
    "    else:\n",
    "      img_all = img_row\n",
    "    img_row = np.array([]) \n",
    "  # ------------------------------------------------\n",
    "\n",
    "  ocr_result = \"\"\n",
    "\n",
    "  # Compare the non-white ratio with the threshold\n",
    "  if non_white_ratio >= 0.03:\n",
    "\n",
    "    # Tesseract \n",
    "    # Specify your whitelist of characters. For example, let's say you want only digits:\n",
    "    ocr_result = pytesseract.image_to_string(ROI, config = r'--psm 13 -c tessedit_char_whitelist=123456789')\n",
    "    #ocr_result = pytesseract.image_to_string(ROI, config = r'--psm 10 --oem 0 -c page_separator=\"\"')\n",
    "\n",
    "    ocr_result = ocr_result.strip()\n",
    "           \n",
    "    print(\"Tesseract OCR Result: \", idx, len(ocr_result), \"->\", ocr_result, \"<-\")\n",
    "    if ( len(ocr_result) == 1 and ocr_result.isdigit() ):\n",
    "       print(\"Yes TESSERACT!\") \n",
    "       SUDOKU_MATRIX_TESSERACT[ii,jj] = int(ocr_result)\n",
    "    elif (len(ocr_result) == 2 and ocr_result=='41'):\n",
    "      print(\"Common problem, hopefully good fix\")\n",
    "      ocr_result = 1\n",
    "      SUDOKU_MATRIX_TESSERACT[ii,jj] = int(ocr_result)\n",
    "    else:\n",
    "      print(\"NOOOOO TESSERACT!\")\n",
    "        \n",
    "#------------------\n",
    "print(\"Tesseract:\\n\", SUDOKU_MATRIX_TESSERACT)\n",
    "printoutStage(6.1,img_all)\n",
    "\n",
    "###################\n",
    "# # Tesseract \n",
    "# # Page segmentation modes:\n",
    "#  0    Orientation and script detection (OSD) only.\n",
    "#  1    Automatic page segmentation with OSD.\n",
    "#  2    Automatic page segmentation, but no OSD, or OCR.\n",
    "#  3    Fully automatic page segmentation, but no OSD. (Default)\n",
    "#  4    Assume a single column of text of variable sizes.\n",
    "#  5    Assume a single uniform block of vertically aligned text.\n",
    "#  6    Assume a single uniform block of text.\n",
    "#  7    Treat the image as a single text line.\n",
    "#  8    Treat the image as a single word.\n",
    "#  9    Treat the image as a single word in a circle.\n",
    "# 10    Treat the image as a single character.\n",
    "# 11    Sparse text. Find as much text as possible in no particular order.\n",
    "# 12    Sparse text with OSD.\n",
    "# 13    Raw line. Treat the image as a single text line,\n",
    "#                        bypassing hacks that are Tesseract-specific.  \n",
    "# OCR Engine modes [oem] \n",
    "# 0 Legacy engine only.\n",
    "# 1 Neural nets LSTM engine only.\n",
    "# 2 Legacy + LSTM engines.\n",
    "# 3 Default, based on what is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each little square box and OCR the digit (another recognizer)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "image = img_gray_aligned_blur_closed\n",
    "#image = img_threshold_aligned_blur_closed\n",
    "image_bw = img_threshold_aligned_blur_closed\n",
    "\n",
    "recognizer = cv2.dnn.readNet('opencv-onnx\\CRNN_VGG_BiLSTM_CTC.onnx')\n",
    "\n",
    "SUDOKU_MATRIX_CNRR = np.zeros([9,9])\n",
    "\n",
    "def decodeText(scores):\n",
    "    text = \"\"\n",
    "    alphabet = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "    #print(scores)\n",
    "    for i in range(scores.shape[0]):\n",
    "        c = np.argmax(scores[i][0][[0,2,3,4,5,6,7,8,9,10]])  # only digits for Sudoku\n",
    "        if c != 0:\n",
    "            #text += alphabet[c - 1]\n",
    "            text += alphabet[c]\n",
    "        else:\n",
    "            text += '-'\n",
    "\n",
    "    # print(text)\n",
    "    \n",
    "    # adjacent same letters as well as background text must be removed to get the final output\n",
    "    char_list = []\n",
    "    for i in range(len(text)):\n",
    "        if text[i] != '-':\n",
    "            char_list.append(text[i])\n",
    "    return ''.join(char_list)\n",
    "\n",
    "for idx in range(81):\n",
    "  \n",
    "  ROI= []\n",
    "\n",
    "  ii = idx//9 \n",
    "  jj = idx%9 \n",
    "\n",
    "  y_min = np.min( [generated_roi_boxes[idx][0][0][1], generated_roi_boxes[idx][1][0][1], generated_roi_boxes[idx][2][0][1], generated_roi_boxes[idx][3][0][1]] )\n",
    "  y_max = np.max( [generated_roi_boxes[idx][0][0][1], generated_roi_boxes[idx][1][0][1], generated_roi_boxes[idx][2][0][1], generated_roi_boxes[idx][3][0][1]] )\n",
    "  x_min = np.min( [generated_roi_boxes[idx][0][0][0], generated_roi_boxes[idx][1][0][0], generated_roi_boxes[idx][2][0][0], generated_roi_boxes[idx][3][0][0]] )\n",
    "  x_max = np.max( [generated_roi_boxes[idx][0][0][0], generated_roi_boxes[idx][1][0][0], generated_roi_boxes[idx][2][0][0], generated_roi_boxes[idx][3][0][0]] )\n",
    "  \n",
    "  # Cut a bit the edges so we eliminate black lines from the grid \n",
    "  delta_x = floor(0.075*(x_max-x_min))  \n",
    "  delta_y = floor(0.075*(y_max-y_min)) \n",
    "\n",
    "  ROI = image[y_min+delta_y:y_max-delta_y, x_min+delta_x:x_max-delta_x]\n",
    "  ROI_bw = image_bw[y_min+delta_y:y_max-delta_y, x_min+delta_x:x_max-delta_x]\n",
    "\n",
    "  non_white_pixels = ( ROI_bw.flatten() < 100 ).sum()\n",
    "  total_pixels = ROI_bw.shape[0] * ROI.shape[1]\n",
    "  non_white_ratio = non_white_pixels / total_pixels\n",
    "  print(\"Non White Ratio Result: \", idx, non_white_ratio)\n",
    "\n",
    "  if non_white_ratio < 0.03:\n",
    "      continue\n",
    "\n",
    "  width_ = ROI.shape[0]\n",
    "  height_ = ROI.shape[1]\n",
    "  printoutStage(98*100+idx*10,ROI)\n",
    " \n",
    "  vertices = [[0,height_],[0,0],[width_,0],[width_, height_]]  \n",
    "  ROI_sized = cv2.resize(ROI, (100,32), interpolation = cv2.INTER_AREA)\n",
    "  printoutStage(98*100+idx*10+2,ROI_sized)\n",
    "\n",
    "  # Create a 4D blob from cropped image\n",
    "  blob = cv2.dnn.blobFromImage(ROI_sized, size=(100, 32), mean=127.5, scalefactor=1.0 / 127.5)\n",
    "  recognizer.setInput(blob)\n",
    "    \n",
    "  # Run the recognition model\n",
    "  result = recognizer.forward()\n",
    "\n",
    "  # decode the result into text\n",
    "  wordRecognized = decodeText(result)\n",
    "  print(wordRecognized)\n",
    "\n",
    "  if len(wordRecognized)==0:\n",
    "      continue\n",
    "  \n",
    "  if len(wordRecognized)>1:\n",
    "      print(\"Multiple Letters:\\t\", wordRecognized)\n",
    "      wordRecognized = wordRecognized[0]\n",
    "  \n",
    "  if wordRecognized=='-':   \n",
    "      continue\n",
    "  \n",
    "  SUDOKU_MATRIX_CNRR[ii,jj] = int(wordRecognized)\n",
    "\n",
    "# ------------------------------------\n",
    "print(\"CNNR:\\n\", SUDOKU_MATRIX_CNRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the two matrices\n",
    "print(\"Tesseract:\\n\", SUDOKU_MATRIX_TESSERACT)\n",
    "print(\"CNNR:\\n\", SUDOKU_MATRIX_CNRR)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
